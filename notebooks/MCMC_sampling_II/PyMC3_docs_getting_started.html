
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>6.5. Getting started with PyMC3 &#8212; Learning from data</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.e8e5499552300ddf5d7adccae7cc3b70.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"TeX": {"Macros": {"N": ["\\mathbb{N}"], "Z": ["\\mathbb{Z}"], "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\left[\\begin{array}"], "emat": ["\\end{array}\\right]"], "muvec": ["\\boldsymbol{\\mu}"], "phivec": ["\\boldsymbol{\\phi}"], "sigmavec": ["\\boldsymbol{\\sigma}"], "Sigmavec": ["\\boldsymbol{\\Sigma}"], "thetavec": ["\\boldsymbol{\\theta}"], "thetavechat": ["\\widehat\\thetavec"], "avec": ["\\boldsymbol{a}"], "Bvec": ["\\boldsymbol{B}"], "xvec": ["\\boldsymbol{x}"], "yvec": ["\\boldsymbol{y}"], "Lra": ["\\Longrightarrow"], "abar": ["\\overline a"], "Xbar": ["\\overline X"], "alphahat": ["\\widehat\\alpha"], "Hhat": ["\\hat H"], "yth": ["y_{\\text{th}}"], "yexp": ["y_{\\text{exp}}"], "ym": ["y_{\\text{m}}"]}}})</script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="7. Gaussian processes" href="../../content/Gaussian_processes/gaussian_processes.html" />
    <link rel="prev" title="6.4. PyMC3 Introduction" href="PyMC3_intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      <img src="../../_static/8820_icon.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Learning from data</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../about.html">
   About this Jupyter Book
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Course overview
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../content/Course/overview.html">
   Objectives
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Topics
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../content/Basics/basics.html">
   1. Basics of Bayesian statistics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../content/Basics/lecture_01.html">
     1.1. Lecture 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Basics/Exploring_pdfs.html">
     1.2. Exploring PDFs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Basics/simple_sum_product_rule.html">
     1.3. Checking the sum and product rules, and their consequences
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../content/Basics/lecture_02.html">
     1.4. Lecture 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Basics/Bayesian_updating_coinflip_interactive.html">
     1.5. Interactive Bayesian updating: coin flipping example
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Basics/medical_example_by_Bayes.html">
     1.6. Standard medical example by applying Bayesian rules of probability
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Basics/radioactive_lighthouse_exercise.html">
     1.7. Radioactive lighthouse problem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../content/Basics/lecture_03.html">
     1.8. Lecture 3
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../content/Parameter_estimation/param_est.html">
   2. Bayesian parameter estimation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../content/Parameter_estimation/lecture_04.html">
     2.1. Lecture 4: Parameter estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Parameter_estimation/parameter_estimation_Gaussian_noise.html">
     2.2. Parameter estimation example: Gaussian noise and averages
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/Assignment_extending_radioactive_lighthouse.html">
     2.3. Assignment: 2D radioactive lighthouse location using MCMC
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../content/Parameter_estimation/lecture_05.html">
     2.4. Lecture 5
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Parameter_estimation/parameter_estimation_fitting_straight_line_I.html">
     2.5. Parameter estimation example: fitting a straight line
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Parameter_estimation/demo-ModelValidation.html">
     2.6. Linear Regression and Model Validation demonstration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../content/Parameter_estimation/lecture_06.html">
     2.7. Lecture 6
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Parameter_estimation/amplitude_in_presence_of_background.html">
     2.8. Amplitude of a signal in the presence of background
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/Assignment_parameter_estimation_followups.html">
     2.9. Assignment: Follow-ups to Parameter Estimation notebooks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Parameter_estimation/exercise_LinearRegression.html">
     2.10. Linear Regression exercise
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Parameter_estimation/linear_algebra_games_I.html">
     2.11. Linear algebra games including SVD for PCA
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../assignments/fluctuation_trend_with_number_of_points_and_data_errors.html">
     2.12. Follow-up: fluctuation trends with # of points and data errors
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../content/MCMC_sampling_I/MCMC_sampling_I.html">
   3. MCMC sampling I
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../content/MCMC_sampling_I/lecture_07.html">
     3.1. Lecture 7
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../MCMC_sampling_I/Metropolis_Poisson_example.html">
     3.2. Metropolis-Hasting MCMC sampling of a Poisson distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../content/MCMC_sampling_I/lecture_08.html">
     3.3. Lecture 8
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../MCMC_sampling_I/MCMC-random-walk-and-sampling.html">
     3.4. Exercise: Random walk
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../content/Why_Bayes_is_better/bayes_is_better.html">
   4. Why Bayes is better
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../content/Why_Bayes_is_better/lecture_09.html">
     4.1. Lecture 9
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Why_Bayes_is_better/bayes_billiard.html">
     4.2. A Bayesian Billiard game
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../content/Why_Bayes_is_better/lecture_10.html">
     4.3. Lecture 10
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Why_Bayes_is_better/parameter_estimation_fitting_straight_line_II.html">
     4.4. Parameter estimation example: fitting a straight line II
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../content/Why_Bayes_is_better/lecture_11.html">
     4.5. Lecture 11
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Why_Bayes_is_better/error_propagation_to_functions_of_uncertain_parameters.html">
     4.6. Error propagation: Example 3.6.2 in Sivia
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Basics/visualization_of_CLT.html">
     4.7. Visualization of the Central Limit Theorem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Basics/correlation_intuition.html">
     4.8. Building intuition about correlations (and a bit of Python linear algebra)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../content/Why_Bayes_is_better/lecture_12.html">
     4.9. Lecture 12
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../MCMC_sampling_I/MCMC-diagnostics.html">
     4.10. Overview: MCMC Diagnostics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../content/Why_Bayes_is_better/lecture_13.html">
     4.12. Lecture 13
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Why_Bayes_is_better/dealing_with_outliers.html">
     4.13. Dealing with outliers
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../content/Model_selection/model_selection.html">
   5. Model selection
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../content/Model_selection/lecture_14.html">
     5.1. Lecture 14
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../content/Model_selection/lecture_15.html">
     5.2. Lecture 15
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Model_selection/Evidence_for_model_EFT_coefficients.html">
     5.3. Evidence calculation for EFT expansions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../content/Model_selection/lecture_16.html">
     5.4. Lecture 16
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../../content/MCMC_sampling_II/MCMC_sampling_II.html">
   6. MCMC sampling II
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="Liouville_theorem_visualization.html">
     6.1. Liouville Theorem Visualization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Orbital_eqs_with_different_algorithms.html">
     6.2. Solving orbital equations with different algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="PyMC3_intro.html">
     6.4. PyMC3 Introduction
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     6.5. Getting started with PyMC3
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../content/Gaussian_processes/gaussian_processes.html">
   7. Gaussian processes
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Gaussian_processes/demo-GaussianProcesses.html">
     7.1. Gaussian processes demonstration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Gaussian_processes/GaussianProcesses.html">
     7.2. Learning from data: Gaussian processes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Gaussian_processes/Gaussian_processes_exercises.html">
     7.3. Exercise: Gaussian Process models with GPy
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../content/Emulators/emulators.html">
   8. Emulators
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../content/Maximum_entropy/max_ent.html">
   9. Assigning probabilities
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Maximum_entropy/demo-MaxEnt.html">
     9.1. Assigning probabilities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Maximum_entropy/MaxEnt.html">
     9.2. Ignorance pdfs: Indifference and translation groups
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Maximum_entropy/Pdfs_from_MaxEnt.html">
     9.3. MaxEnt for deriving probability distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Maximum_entropy/MaxEnt_Function_Reconstruction.html">
     9.4. Maximum Entropy for reconstructing a function from its moments
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../content/Machine_learning/machine_learning.html">
   10. Machine learning: Bayesian methods
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Machine_learning/Bayesian_optimization.html">
     10.1. Physics 8805
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../content/SVD/svd.html">
   11. PCA, SVD, and all that
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../SVD/linear_algebra_games_including_SVD.html">
     11.1. Linear algebra games including SVD for PCA
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../content/Model_mixing/model_mixing.html">
   12. Model mixing
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Mini-projects
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../mini-projects/mini-project_I_toy_model_of_EFT.html">
   Mini-project I: Parameter estimation for a toy model of an EFT
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mini-projects/model-selection_mini-project-IIa.html">
   Mini-project IIa: Model selection basics
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Reference material
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../content/zbibliography.html">
   Bibliography
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../content/related_topics.html">
   Related topics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../content/Reference/installing_anaconda.html">
   Using Anaconda
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../content/Reference/using_github.html">
   Using GitHub
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../content/Reference/python_jupyter.html">
   Python and Jupyter notebooks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Reference/Jupyter_Python_intro_01.html">
     Python and Jupyter notebooks: part 01
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Reference/Jupyter_Python_intro_02.html">
     Python and Jupyter notebooks: part 02
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../content/jb_tests.html">
   Examples: Jupyter jb-book
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Notebook keys
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Basics/simple_sum_product_rule_KEY.html">
   Checking the sum and product rules, and their consequences
   <span style="color: red">
    Key
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Basics/medical_example_by_Bayes_KEY.html">
   Standard medical example by applying Bayesian rules of probability
   <span style="color: red">
    Key
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Basics/radioactive_lighthouse_exercise_key.html">
   Radioactive lighthouse problem
   <span style="color: red">
    Key
   </span>
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/notebooks/MCMC_sampling_II/PyMC3_docs_getting_started.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/furnstahl/Physics-8820"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/furnstahl/Physics-8820/issues/new?title=Issue%20on%20page%20%2Fnotebooks/MCMC_sampling_II/PyMC3_docs_getting_started.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/furnstahl/Physics-8820/main?urlpath=tree/./LectureNotes/notebooks/MCMC_sampling_II/PyMC3_docs_getting_started.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#features-of-pymc3">
   Features of PyMC3
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-motivating-example-linear-regression">
   A Motivating Example: Linear Regression
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generating-data">
     Generating data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-specification">
     Model Specification
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-fitting">
     Model fitting
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#maximum-a-posteriori-methods">
       Maximum a posteriori methods
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#sampling-methods">
       Sampling methods
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#gradient-based-sampling-methods">
       Gradient-based sampling methods
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#posterior-analysis">
     Posterior analysis
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#case-study-1-stochastic-volatility">
   Case study 1: Stochastic volatility
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-model">
     The Model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-data">
     The Data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Model Specification
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fitting">
     Fitting
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#case-study-2-coal-mining-disasters">
   Case study 2: Coal mining disasters
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#arbitrary-deterministics">
   Arbitrary deterministics
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#arbitrary-distributions">
   Arbitrary distributions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#generalized-linear-models">
   Generalized Linear Models
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#discussion">
   Discussion
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="getting-started-with-pymc3">
<h1><span class="section-number">6.5. </span>Getting started with PyMC3<a class="headerlink" href="#getting-started-with-pymc3" title="Permalink to this headline">¶</a></h1>
<p>Based on a notebook by John Salvatier, Thomas V. Wiecki, Christopher Fonnesbeck from [<a class="reference external" href="https://docs.pymc.io/notebooks/getting_started.html">https://docs.pymc.io/notebooks/getting_started.html</a>].</p>
<div class="section" id="features-of-pymc3">
<h2>Features of PyMC3<a class="headerlink" href="#features-of-pymc3" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>PyMC3 is an open source Probabilistic Programming framework written in Python.  It uses Theano to calculated gradients it needs for HMC using automatic differentiation.</p></li>
<li><p>PyMC3 compiles probabilistic programs on-the-fly to C for increased speed.</p></li>
<li><p>It allows models to be specified directly in Python (cf. PyStan) with intuitive and readable syntax, that mimics the synta used by statisticians.</p></li>
<li><p>“It features next-generation Markov chain Monte Carlo (MCMC) sampling algorithms such as the No-U-Turn Sampler (NUTS; Hoffman, 2014), a self-tuning variant of Hamiltonian Monte Carlo (HMC; Duane, 1987). This class of samplers works well on high dimensional and complex posterior distributions and allows many complex models to be fit without specialized knowledge about fitting algorithms.”</p></li>
<li><p>NUTS has self-tuning strategies to set HMC tunable parameters adaptively.</p></li>
<li><p>About Theano: “Theano is a library that allows expressions to be defined using generalized vector data structures called <em>tensors</em>, which are tightly integrated with the popular NumPy <code class="docutils literal notranslate"><span class="pre">ndarray</span></code> data structure, and similarly allow for broadcasting and advanced indexing, just as NumPy arrays do. Theano also automatically optimizes the likelihood’s computational graph for speed and provides simple GPU integration.”</p></li>
</ul>
</div>
<div class="section" id="a-motivating-example-linear-regression">
<h2>A Motivating Example: Linear Regression<a class="headerlink" href="#a-motivating-example-linear-regression" title="Permalink to this headline">¶</a></h2>
<p>To introduce model definition, fitting and posterior analysis, we first consider a simple Bayesian linear regression model with normal priors for the parameters. We are interested in predicting outcomes <span class="math notranslate nohighlight">\(Y\)</span> as normally-distributed observations with an expected value <span class="math notranslate nohighlight">\(\mu\)</span> that is a linear function of two predictor variables, <span class="math notranslate nohighlight">\(X_1\)</span> and <span class="math notranslate nohighlight">\(X_2\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned} 
Y  &amp;\sim \mathcal{N}(\mu, \sigma^2) \\
\mu &amp;= \alpha + \beta_1 X_1 + \beta_2 X_2
\end{aligned}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\alpha\)</span> is the intercept, and <span class="math notranslate nohighlight">\(\beta_i\)</span> is the coefficient for covariate <span class="math notranslate nohighlight">\(X_i\)</span>, while <span class="math notranslate nohighlight">\(\sigma\)</span> represents the observation error. Since we are constructing a Bayesian model, we must assign a prior distribution to the unknown variables in the model. We choose zero-mean normal priors with variance of 100 for both regression coefficients, which corresponds to <em>weak</em> information regarding the true parameter values. We choose a half-normal distribution (normal distribution bounded at zero) as the prior for <span class="math notranslate nohighlight">\(\sigma\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned} 
\alpha &amp;\sim \mathcal{N}(0, 100) \\
\beta_i &amp;\sim \mathcal{N}(0, 100) \\
\sigma &amp;\sim \lvert\mathcal{N}(0, 1){\rvert}
\end{aligned}\end{split}\]</div>
<div class="section" id="generating-data">
<h3>Generating data<a class="headerlink" href="#generating-data" title="Permalink to this headline">¶</a></h3>
<p>We can simulate some artificial data from this model using only NumPy’s <code class="docutils literal notranslate"><span class="pre">random</span></code> module, and then use PyMC3 to try to recover the corresponding parameters. We are intentionally generating the data to closely correspond the PyMC3 model structure.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;seaborn-darkgrid&#39;</span><span class="p">)</span>

<span class="c1"># Initialize random number generator</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>

<span class="c1"># True parameter values</span>
<span class="n">alpha</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span>
<span class="n">beta</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">]</span>

<span class="c1"># Size of dataset</span>
<span class="n">size</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># Predictor variable</span>
<span class="n">X1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
<span class="n">X2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.2</span>

<span class="c1"># Simulate outcome variable</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">+</span> <span class="n">beta</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">X1</span> <span class="o">+</span> <span class="n">beta</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">X2</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="p">)</span><span class="o">*</span><span class="n">sigma</span>
</pre></div>
</div>
</div>
</div>
<p>Here is what the simulated data look like.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline 

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X2</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">);</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;X1&#39;</span><span class="p">);</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;X2&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/PyMC3_docs_getting_started_5_0.png" src="../../_images/PyMC3_docs_getting_started_5_0.png" />
</div>
</div>
</div>
<div class="section" id="model-specification">
<h3>Model Specification<a class="headerlink" href="#model-specification" title="Permalink to this headline">¶</a></h3>
<p>Specifying this model in PyMC3 is straightforward because the syntax is as close to the statistical notation. For the most part, each line of Python code corresponds to a line in the model notation above.</p>
<p>First, we import PyMC. We use the convention of importing it as <code class="docutils literal notranslate"><span class="pre">pm</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pymc3</span> <span class="k">as</span> <span class="nn">pm</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Running on PyMC3 v</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pm</span><span class="o">.</span><span class="n">__version__</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Running on PyMC3 v3.7
</pre></div>
</div>
</div>
</div>
<p>Now we build our model, which we will present in full first, then explain each part line-by-line.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">basic_model</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span>

<span class="k">with</span> <span class="n">basic_model</span><span class="p">:</span>
    
    <span class="c1"># Priors for unknown model parameters</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;alpha&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s1">&#39;sigma&#39;</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Expected value of outcome</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">+</span> <span class="n">beta</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">X1</span> <span class="o">+</span> <span class="n">beta</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">X2</span>
    
    <span class="c1"># Likelihood (sampling distribution) of observations</span>
    <span class="n">Y_obs</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;Y_obs&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">Y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The first line,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">basic_model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">()</span>
</pre></div>
</div>
<p>creates a new <code class="docutils literal notranslate"><span class="pre">Model</span></code> object which is a container for the model random variables.</p>
<p>Following instantiation of the model, the subsequent specification of the model components is performed inside a  <code class="docutils literal notranslate"><span class="pre">with</span></code> statement:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">basic_model</span><span class="p">:</span>
</pre></div>
</div>
<p>This creates a <em>context manager</em>, with our <code class="docutils literal notranslate"><span class="pre">basic_model</span></code> as the context, that includes all statements until the indented block ends. This means all PyMC3 objects introduced in the indented code block below the <code class="docutils literal notranslate"><span class="pre">with</span></code> statement are added to the model behind the scenes. Absent this context manager idiom, we would be forced to manually associate each of the variables with <code class="docutils literal notranslate"><span class="pre">basic_model</span></code> right after we create them. If you try to create a new random variable without a <code class="docutils literal notranslate"><span class="pre">with</span> <span class="pre">model:</span></code> statement, it will raise an error since there is no obvious model for the variable to be added to.</p>
<p>The first three statements in the context manager:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">alpha</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;alpha&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">beta</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="n">HalfNormal</span><span class="p">(</span><span class="s1">&#39;sigma&#39;</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>create <strong>stochastic</strong> random variables with Normal prior distributions for the regression coefficients with a mean of 0 and standard deviation of 10, and a half-normal distribution for the standard deviation of the observations, <span class="math notranslate nohighlight">\(\sigma\)</span>. These are stochastic because their values are partly determined by its parents in the dependency graph of random variables, which for priors are simple constants, and partly random (or stochastic).</p>
<p>We call the <code class="docutils literal notranslate"><span class="pre">Normal</span></code> constructor to create a random variable to use as a normal prior. The first argument is always the <em>name</em> of the random variable, which should almost always match the name of the Python variable being assigned to, since it is sometimes used to retrieve the variable from the model for summarizing output. The remaining required arguments for a stochastic object are the parameters, in this case <code class="docutils literal notranslate"><span class="pre">mu</span></code>, the mean, and <code class="docutils literal notranslate"><span class="pre">sd</span></code>, the standard deviation, which we assign hyperparameter values for the model. In general, a distribution’s parameters are values that determine the location, shape or scale of the random variable, depending on the parameterization of the distribution. Most commonly used distributions, such as <code class="docutils literal notranslate"><span class="pre">Beta</span></code>, <code class="docutils literal notranslate"><span class="pre">Exponential</span></code>, <code class="docutils literal notranslate"><span class="pre">Categorical</span></code>, <code class="docutils literal notranslate"><span class="pre">Gamma</span></code>, <code class="docutils literal notranslate"><span class="pre">Binomial</span></code> and many others, are available in PyMC3.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">beta</span></code> variable has an additional <code class="docutils literal notranslate"><span class="pre">shape</span></code> argument to denote it as a vector-valued parameter of size 2. The <code class="docutils literal notranslate"><span class="pre">shape</span></code> argument is available for all distributions and specifies the length or shape of the random variable, but is optional for scalar variables, since it defaults to a value of one. It can be an integer, to specify an array, or a tuple, to specify a multidimensional array (<em>e.g.</em> <code class="docutils literal notranslate"><span class="pre">shape=(5,7)</span></code> makes random variable that takes on 5 by 7 matrix values).</p>
<p>Detailed notes about distributions, sampling methods and other PyMC3 functions are available in the <a class="reference external" href="https://docs.pymc.io/api.html">API documentation</a>.</p>
<p>Having defined the priors, the next statement creates the expected value <code class="docutils literal notranslate"><span class="pre">mu</span></code> of the outcomes, specifying the linear relationship:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mu</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">+</span> <span class="n">beta</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">X1</span> <span class="o">+</span> <span class="n">beta</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">X2</span>
</pre></div>
</div>
<p>This creates a <strong>deterministic</strong> random variable, which implies that its value is <em>completely</em> determined by its parents’ values. That is, there is no uncertainty beyond that which is inherent in the parents’ values. Here, <code class="docutils literal notranslate"><span class="pre">mu</span></code> is just the sum of the intercept <code class="docutils literal notranslate"><span class="pre">alpha</span></code> and the two products of the coefficients in <code class="docutils literal notranslate"><span class="pre">beta</span></code> and the predictor variables, whatever their values may be.</p>
<p>PyMC3 random variables and data can be arbitrarily added, subtracted, divided, multiplied together and indexed-into to create new random variables. This allows for great model expressivity. Many common mathematical functions like <code class="docutils literal notranslate"><span class="pre">sum</span></code>, <code class="docutils literal notranslate"><span class="pre">sin</span></code>, <code class="docutils literal notranslate"><span class="pre">exp</span></code> and linear algebra functions like <code class="docutils literal notranslate"><span class="pre">dot</span></code> (for inner product) and <code class="docutils literal notranslate"><span class="pre">inv</span></code> (for inverse) are also provided.</p>
<p>The final line of the model, defines <code class="docutils literal notranslate"><span class="pre">Y_obs</span></code>, the sampling distribution of the outcomes in the dataset.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Y_obs</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;Y_obs&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">Y</span><span class="p">)</span>
</pre></div>
</div>
<p>This is a special case of a stochastic variable that we call an <strong>observed stochastic</strong>, and represents the data likelihood of the model. It is identical to a standard stochastic, except that its <code class="docutils literal notranslate"><span class="pre">observed</span></code> argument, which passes the data to the variable, indicates that the values for this variable were observed, and should not be changed by any fitting algorithm applied to the model. The data can be passed in the form of either a <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code> or <code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code> object.</p>
<p>Notice that, unlike for the priors of the model, the parameters for the normal distribution of <code class="docutils literal notranslate"><span class="pre">Y_obs</span></code> are not fixed values, but rather are the deterministic object <code class="docutils literal notranslate"><span class="pre">mu</span></code> and the stochastic <code class="docutils literal notranslate"><span class="pre">sigma</span></code>. This creates parent-child relationships between the likelihood and these two variables.</p>
</div>
<div class="section" id="model-fitting">
<h3>Model fitting<a class="headerlink" href="#model-fitting" title="Permalink to this headline">¶</a></h3>
<p>Having completely specified our model, the next step is to obtain posterior estimates for the unknown variables in the model. Ideally, we could calculate the posterior estimates analytically, but for most non-trivial models, this is not feasible. We will consider two approaches, whose appropriateness depends on the structure of the model and the goals of the analysis: finding the <em>maximum a posteriori</em> (MAP) point using optimization methods, and computing summaries based on samples drawn from the posterior distribution using Markov Chain Monte Carlo (MCMC) sampling methods.</p>
<div class="section" id="maximum-a-posteriori-methods">
<h4>Maximum a posteriori methods<a class="headerlink" href="#maximum-a-posteriori-methods" title="Permalink to this headline">¶</a></h4>
<p>The <strong>maximum a posteriori (MAP)</strong> estimate for a model, is the mode of the posterior distribution and is generally found using numerical optimization methods. This is often fast and easy to do, but only gives a point estimate for the parameters and can be biased if the mode isn’t representative of the distribution. PyMC3 provides this functionality with the <code class="docutils literal notranslate"><span class="pre">find_MAP</span></code> function.</p>
<p>Below we find the MAP for our original model. The MAP is returned as a parameter <strong>point</strong>, which is always represented by a Python dictionary of variable names to NumPy arrays of parameter values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">map_estimate</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">find_MAP</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">basic_model</span><span class="p">)</span>
    
<span class="n">map_estimate</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/furnstah/anaconda3/envs/talent-env/lib/python3.7/site-packages/pymc3/tuning/starting.py:61: UserWarning: find_MAP should not be used to initialize the NUTS sampler, simply call pymc3.sample() and it will automatically initialize NUTS in a better way.
  warnings.warn(&#39;find_MAP should not be used to initialize the NUTS sampler, simply call pymc3.sample() and it will automatically initialize NUTS in a better way.&#39;)
logp = -149.58, ||grad|| = 12.242: 100%|██████████| 19/19 [00:00&lt;00:00, 1470.95it/s]  
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;alpha&#39;: array(0.90660093),
 &#39;beta&#39;: array([0.94848596, 2.60711845]),
 &#39;sigma_log__&#39;: array(-0.03771373),
 &#39;sigma&#39;: array(0.96298858)}
</pre></div>
</div>
</div>
</div>
<p>By default, <code class="docutils literal notranslate"><span class="pre">find_MAP</span></code> uses the Broyden–Fletcher–Goldfarb–Shanno (BFGS) optimization algorithm to find the maximum of the log-posterior but also allows selection of other optimization algorithms from the <code class="docutils literal notranslate"><span class="pre">scipy.optimize</span></code> module. For example, below we use Powell’s method to find the MAP.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">map_estimate</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">find_MAP</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">basic_model</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;powell&#39;</span><span class="p">)</span>
    
<span class="n">map_estimate</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/furnstah/anaconda3/envs/talent-env/lib/python3.7/site-packages/pymc3/tuning/starting.py:61: UserWarning: find_MAP should not be used to initialize the NUTS sampler, simply call pymc3.sample() and it will automatically initialize NUTS in a better way.
  warnings.warn(&#39;find_MAP should not be used to initialize the NUTS sampler, simply call pymc3.sample() and it will automatically initialize NUTS in a better way.&#39;)
  0%|          | 0/5000 [00:00&lt;?, ?it/s]/Users/furnstah/anaconda3/envs/talent-env/lib/python3.7/site-packages/scipy/optimize/_minimize.py:500: RuntimeWarning: Method powell does not use gradient information (jac).
  RuntimeWarning)
logp = -149.47, ||grad|| = 13.248: 100%|██████████| 177/177 [00:00&lt;00:00, 2409.74it/s] 
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;alpha&#39;: array(0.90907964),
 &#39;beta&#39;: array([0.9514399 , 2.61452795]),
 &#39;sigma_log__&#39;: array(-0.03492212),
 &#39;sigma&#39;: array(0.96568062)}
</pre></div>
</div>
</div>
</div>
<p>It is important to note that the MAP estimate is not always reasonable, especially if the mode is at an extreme. This can be a subtle issue; with high dimensional posteriors, one can have areas of extremely high density but low total probability because the volume is very small. This will often occur in hierarchical models with the variance parameter for the random effect. If the individual group means are all the same, the posterior will have near infinite density if the scale parameter for the group means is almost zero, even though the probability of such a small scale parameter will be small since the group means must be extremely close together.</p>
<p>Most techniques for finding the MAP estimate also only find a <em>local</em> optimum (which is often good enough), but can fail badly for multimodal posteriors if the different modes are meaningfully different.</p>
<p>In summary, while PyMC3 provides the function <code class="docutils literal notranslate"><span class="pre">find_MAP()</span></code>, at this point mostly for historical reasons, this function is of little use in most scenarios. If you want a point estimate you should get it from the posterior. In the next section we will see how to get a posterior using sampling methods.</p>
</div>
<div class="section" id="sampling-methods">
<h4>Sampling methods<a class="headerlink" href="#sampling-methods" title="Permalink to this headline">¶</a></h4>
<p>Though finding the MAP is a fast and easy way of obtaining estimates of the unknown model parameters, it is limited because there is no associated estimate of uncertainty produced with the MAP estimates. Instead, a simulation-based approach such as Markov chain Monte Carlo (MCMC) can be used to obtain a Markov chain of values that, given the satisfaction of certain conditions, are indistinguishable from samples from the <em>true</em> posterior distribution.</p>
<p>To conduct MCMC sampling to generate posterior samples in PyMC3, we specify a <strong>step method</strong> object that corresponds to a particular MCMC algorithm, such as Metropolis, Slice sampling, or the No-U-Turn Sampler (NUTS). PyMC3’s <code class="docutils literal notranslate"><span class="pre">step_methods</span></code> submodule contains the following samplers: <code class="docutils literal notranslate"><span class="pre">NUTS</span></code>, <code class="docutils literal notranslate"><span class="pre">Metropolis</span></code>, <code class="docutils literal notranslate"><span class="pre">Slice</span></code>, <code class="docutils literal notranslate"><span class="pre">HamiltonianMC</span></code>, and <code class="docutils literal notranslate"><span class="pre">BinaryMetropolis</span></code>. These step methods can be assigned manually, or assigned automatically by PyMC3. Auto-assignment is based on the attributes of each variable in the model. In general:</p>
<ul class="simple">
<li><p>Binary variables will be assigned to <code class="docutils literal notranslate"><span class="pre">BinaryMetropolis</span></code></p></li>
<li><p>Discrete variables will be assigned to <code class="docutils literal notranslate"><span class="pre">Metropolis</span></code></p></li>
<li><p>Continuous variables will be assigned to <code class="docutils literal notranslate"><span class="pre">NUTS</span></code></p></li>
</ul>
<p>Auto-assignment can be overriden for any subset of variables by specifying them manually prior to sampling.</p>
</div>
<div class="section" id="gradient-based-sampling-methods">
<h4>Gradient-based sampling methods<a class="headerlink" href="#gradient-based-sampling-methods" title="Permalink to this headline">¶</a></h4>
<p>PyMC3 has the standard sampling algorithms like adaptive Metropolis-Hastings and adaptive slice sampling, but PyMC3’s most capable step method is the No-U-Turn Sampler. NUTS is especially useful on models that have many continuous parameters, a situation where other MCMC algorithms work very slowly. It takes advantage of information about where regions of higher probability are, based on the gradient of the log posterior-density. This helps it achieve dramatically faster convergence on large problems than traditional sampling methods achieve. PyMC3 relies on Theano to analytically compute model gradients via automatic differentiation of the posterior density. NUTS also has several self-tuning strategies for adaptively setting the tunable parameters of Hamiltonian Monte Carlo. For random variables that are undifferentiable (namely, discrete variables) NUTS cannot be used, but it may still be used on the differentiable variables in a model that contains undifferentiable variables.</p>
<p>NUTS requires a scaling matrix parameter, which is analogous to the variance parameter for the jump proposal distribution in Metropolis-Hastings, although NUTS uses it somewhat differently. The matrix gives the rough shape of the distribution so that NUTS does not make jumps that are too large in some directions and too small in other directions. It is important to set this scaling parameter to a reasonable value to facilitate efficient sampling. This is especially true for models that have many unobserved stochastic random variables or models with highly non-normal posterior distributions. Poor scaling parameters will slow down NUTS significantly, sometimes almost stopping it completely. A reasonable starting point for sampling can also be important for efficient sampling, but not as often.</p>
<p><code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> automatically initializes NUTS to reasonable values based on the variance of the samples obtained during a tuning phase. A little bit of noise is added to ensure different, parallel, chains start from different points. Also, <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> will automatically assign an appropriate sampler if we don’t supply it via the <code class="docutils literal notranslate"><span class="pre">step</span></code> keyword argument (see below for an example of how to explicitly assign step methods).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">basic_model</span><span class="p">:</span>
    <span class="c1"># draw 500 posterior samples</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">500</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [sigma, beta, alpha]
Sampling 4 chains: 100%|██████████| 4000/4000 [00:01&lt;00:00, 2396.84draws/s]
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">sample</span></code> function runs the step method(s) assigned (or passed) to it for the given number of iterations and returns a <code class="docutils literal notranslate"><span class="pre">Trace</span></code> object containing the samples collected, in the order they were collected. The <code class="docutils literal notranslate"><span class="pre">trace</span></code> object can be queried in a similar way to a <code class="docutils literal notranslate"><span class="pre">dict</span></code> containing a map from variable names to <code class="docutils literal notranslate"><span class="pre">numpy.array</span></code>s. The first dimension of the array is the sampling index and the later dimensions match the shape of the variable. We can see the last 5 values for the <code class="docutils literal notranslate"><span class="pre">alpha</span></code> variable as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;alpha&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">5</span><span class="p">:]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.9022226 , 0.87236601, 0.96473987, 0.79315611, 0.67644667])
</pre></div>
</div>
</div>
</div>
<p>If we wanted to use the slice sampling algorithm to <code class="docutils literal notranslate"><span class="pre">sigma</span></code> instead of NUTS (which was assigned automatically), we could have specified this as the <code class="docutils literal notranslate"><span class="pre">step</span></code> argument for <code class="docutils literal notranslate"><span class="pre">sample</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">basic_model</span><span class="p">:</span>

    <span class="c1"># instantiate sampler</span>
    <span class="n">step</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Slice</span><span class="p">()</span> 
    
    <span class="c1"># draw 5000 posterior samples</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">5000</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">step</span><span class="p">)</span>   
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Multiprocess sampling (4 chains in 4 jobs)
CompoundStep
&gt;Slice: [sigma]
&gt;Slice: [beta]
&gt;Slice: [alpha]
Sampling 4 chains: 100%|██████████| 22000/22000 [00:23&lt;00:00, 948.79draws/s] 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="posterior-analysis">
<h3>Posterior analysis<a class="headerlink" href="#posterior-analysis" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> provides plotting and summarization functions for inspecting the sampling output. A simple posterior plot can be created using <code class="docutils literal notranslate"><span class="pre">traceplot</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pm</span><span class="o">.</span><span class="n">traceplot</span><span class="p">(</span><span class="n">trace</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/PyMC3_docs_getting_started_25_0.png" src="../../_images/PyMC3_docs_getting_started_25_0.png" />
</div>
</div>
<p>The left column consists of a smoothed histogram (using kernel density estimation) of the marginal posteriors of each stochastic random variable while the right column contains the samples of the Markov chain plotted in sequential order. The <code class="docutils literal notranslate"><span class="pre">beta</span></code> variable, being vector-valued, produces two histograms and two sample traces, corresponding to both predictor coefficients.</p>
<p>In addition, the <code class="docutils literal notranslate"><span class="pre">summary</span></code> function provides a text-based output of common posterior statistics:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pm</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>mc_error</th>
      <th>hpd_2.5</th>
      <th>hpd_97.5</th>
      <th>n_eff</th>
      <th>Rhat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>alpha</th>
      <td>0.91</td>
      <td>0.10</td>
      <td>0.0</td>
      <td>0.72</td>
      <td>1.11</td>
      <td>19979.81</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>beta__0</th>
      <td>0.95</td>
      <td>0.09</td>
      <td>0.0</td>
      <td>0.78</td>
      <td>1.13</td>
      <td>19107.16</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>beta__1</th>
      <td>2.65</td>
      <td>0.52</td>
      <td>0.0</td>
      <td>1.60</td>
      <td>3.65</td>
      <td>16191.09</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>sigma</th>
      <td>0.99</td>
      <td>0.07</td>
      <td>0.0</td>
      <td>0.86</td>
      <td>1.13</td>
      <td>17898.13</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</div>
</div>
<div class="section" id="case-study-1-stochastic-volatility">
<h2>Case study 1: Stochastic volatility<a class="headerlink" href="#case-study-1-stochastic-volatility" title="Permalink to this headline">¶</a></h2>
<p>We present a case study of stochastic volatility, time varying stock market volatility, to illustrate PyMC3’s use in addressing a more realistic problem. The distribution of market returns is highly non-normal, which makes sampling the volatilities significantly more difficult. This example has 400+ parameters so using common sampling algorithms like Metropolis-Hastings would get bogged down, generating highly autocorrelated samples. Instead, we use NUTS, which is dramatically more efficient.</p>
<div class="section" id="the-model">
<h3>The Model<a class="headerlink" href="#the-model" title="Permalink to this headline">¶</a></h3>
<p>Asset prices have time-varying volatility (variance of day over day <code class="docutils literal notranslate"><span class="pre">returns</span></code>). In some periods, returns are highly variable, while in others they are very stable. Stochastic volatility models address this with a latent volatility variable, which changes over time. The following model is similar to the one described in the NUTS paper (Hoffman 2014, p. 21).</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned} 
  \nu &amp;\sim exp(0.1) \\
  \sigma &amp;\sim exp(50) \\
  s_i &amp;\sim \mathcal{N}(s_{i-1}, \sigma^2) \\
  log(r_i) &amp;\sim t(\nu, 0, exp(-2 s_i))
\end{aligned}
\end{split}\]</div>
<p>Here, <span class="math notranslate nohighlight">\(r\)</span> is the daily return series which is modeled with a Student-t distribution with an unknown degrees of freedom parameter, and a scale parameter determined by a latent process <span class="math notranslate nohighlight">\(s\)</span>. The individual <span class="math notranslate nohighlight">\(s_i\)</span> are the individual daily log volatilities in the latent log volatility process.</p>
</div>
<div class="section" id="the-data">
<h3>The Data<a class="headerlink" href="#the-data" title="Permalink to this headline">¶</a></h3>
<p>Our data consist of 401 daily returns of the S&amp;P 500 stock market index during the 2008 financial crisis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">returns</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">pm</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="s1">&#39;SP500.csv&#39;</span><span class="p">),</span> <span class="n">parse_dates</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="nb">len</span><span class="p">(</span><span class="n">returns</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>401
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">returns</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;daily returns in %&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/PyMC3_docs_getting_started_31_0.png" src="../../_images/PyMC3_docs_getting_started_31_0.png" />
</div>
</div>
</div>
<div class="section" id="id1">
<h3>Model Specification<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>As with the linear regression example, specifying the model in PyMC3 mirrors its statistical specification. This model employs several new distributions: the <code class="docutils literal notranslate"><span class="pre">Exponential</span></code> distribution for the <span class="math notranslate nohighlight">\(\nu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> priors, the Student-T (<code class="docutils literal notranslate"><span class="pre">StudentT</span></code>) distribution for distribution of returns, and the <code class="docutils literal notranslate"><span class="pre">GaussianRandomWalk</span></code> for the prior for the latent volatilities.</p>
<p>In PyMC3, variables with purely positive priors like <code class="docutils literal notranslate"><span class="pre">Exponential</span></code> are transformed with a log transform. This makes sampling more robust. Behind the scenes, a variable in the unconstrained space (named “variableName_log”) is added to the model for sampling. In this model this happens behind the scenes for both the degrees of freedom, <code class="docutils literal notranslate"><span class="pre">nu</span></code>, and the scale parameter for the volatility process, <code class="docutils literal notranslate"><span class="pre">sigma</span></code>, since they both have exponential priors. Variables with priors that constrain them on two sides, like <code class="docutils literal notranslate"><span class="pre">Beta</span></code> or <code class="docutils literal notranslate"><span class="pre">Uniform</span></code>, are also transformed to be unconstrained but with a log odds transform.</p>
<p>Although, unlike model specification in PyMC2, we do not typically provide starting points for variables at the model specification stage, we can also provide an initial value for any distribution (called a “test value”) using the <code class="docutils literal notranslate"><span class="pre">testval</span></code> argument. This overrides the default test value for the distribution (usually the mean, median or mode of the distribution), and is most often useful if some values are illegal and we want to ensure we select a legal one. The test values for the distributions are also used as a starting point for sampling and optimization by default, though this is easily overriden.</p>
<p>The vector of latent volatilities <code class="docutils literal notranslate"><span class="pre">s</span></code> is given a prior distribution by <code class="docutils literal notranslate"><span class="pre">GaussianRandomWalk</span></code>. As its name suggests GaussianRandomWalk is a vector valued distribution where the values of the vector form a random normal walk of length n, as specified by the <code class="docutils literal notranslate"><span class="pre">shape</span></code> argument. The scale of the innovations of the random walk, <code class="docutils literal notranslate"><span class="pre">sigma</span></code>, is specified in terms of the standard deviation of the normally distributed innovations and can be a scalar or vector.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">sp500_model</span><span class="p">:</span>
    <span class="n">nu</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;nu&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mf">10.</span><span class="p">,</span> <span class="n">testval</span><span class="o">=</span><span class="mf">5.</span><span class="p">)</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;sigma&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">testval</span><span class="o">=</span><span class="mf">.1</span><span class="p">)</span>

    <span class="n">s</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">GaussianRandomWalk</span><span class="p">(</span><span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="n">sigma</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">returns</span><span class="p">))</span>
    <span class="n">volatility_process</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;volatility_process&#39;</span><span class="p">,</span> <span class="n">pm</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">s</span><span class="p">)</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>

    <span class="n">r</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">StudentT</span><span class="p">(</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="n">nu</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="n">volatility_process</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">returns</span><span class="p">[</span><span class="s1">&#39;change&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Notice that we transform the log volatility process <code class="docutils literal notranslate"><span class="pre">s</span></code> into the volatility process by <code class="docutils literal notranslate"><span class="pre">exp(-2*s)</span></code>. Here, <code class="docutils literal notranslate"><span class="pre">exp</span></code> is a Theano function, rather than the corresponding function in NumPy; Theano provides a large subset of the mathematical functions that NumPy does.</p>
<p>Also note that we have declared the <code class="docutils literal notranslate"><span class="pre">Model</span></code> name <code class="docutils literal notranslate"><span class="pre">sp500_model</span></code> in the first occurrence of the context manager, rather than splitting it into two lines, as we did for the first example.</p>
</div>
<div class="section" id="fitting">
<h3>Fitting<a class="headerlink" href="#fitting" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">sp500_model</span><span class="p">:</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">2000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [s, sigma, nu]
Sampling 4 chains: 100%|██████████| 10000/10000 [03:42&lt;00:00, 44.93draws/s]
The estimated number of effective samples is smaller than 200 for some parameters.
</pre></div>
</div>
</div>
</div>
<p>We can check our samples by looking at the traceplot for <code class="docutils literal notranslate"><span class="pre">nu</span></code> and <code class="docutils literal notranslate"><span class="pre">sigma</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pm</span><span class="o">.</span><span class="n">traceplot</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="n">varnames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;nu&#39;</span><span class="p">,</span> <span class="s1">&#39;sigma&#39;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/furnstah/anaconda3/envs/talent-env/lib/python3.7/site-packages/pymc3/plots/__init__.py:40: UserWarning: Keyword argument `varnames` renamed to `var_names`, and will be removed in pymc3 3.8
  warnings.warn(&#39;Keyword argument `{old}` renamed to `{new}`, and will be removed in pymc3 3.8&#39;.format(old=old, new=new))
</pre></div>
</div>
<img alt="../../_images/PyMC3_docs_getting_started_38_1.png" src="../../_images/PyMC3_docs_getting_started_38_1.png" />
</div>
</div>
<p>Finally we plot the distribution of volatility paths by plotting many of our sampled volatility paths on the same graph. Each is rendered partially transparent (via the <code class="docutils literal notranslate"><span class="pre">alpha</span></code> argument in Matplotlib’s <code class="docutils literal notranslate"><span class="pre">plot</span></code> function) so the regions where many paths overlap are shaded more darkly.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">returns</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">returns</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;s&#39;</span><span class="p">,::</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">),</span> <span class="s1">&#39;C3&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.03</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;volatility_process&#39;</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;time&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;volatility&#39;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;S&amp;P500&#39;</span><span class="p">,</span> <span class="s1">&#39;stochastic volatility process&#39;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/furnstah/anaconda3/envs/talent-env/lib/python3.7/site-packages/IPython/core/events.py:88: UserWarning: Creating legend with loc=&quot;best&quot; can be slow with large amounts of data.
  func(*args, **kwargs)
/Users/furnstah/anaconda3/envs/talent-env/lib/python3.7/site-packages/IPython/core/pylabtools.py:128: UserWarning: Creating legend with loc=&quot;best&quot; can be slow with large amounts of data.
  fig.canvas.print_figure(bytes_io, **kw)
</pre></div>
</div>
<img alt="../../_images/PyMC3_docs_getting_started_40_1.png" src="../../_images/PyMC3_docs_getting_started_40_1.png" />
</div>
</div>
<p>As you can see, the model correctly infers the increase in volatility during the 2008 financial crash. Moreover, note that this model is quite complex because of its high dimensionality and dependency-structure in the random walk distribution. NUTS as implemented in PyMC3, however, correctly infers the posterior distribution with ease.</p>
</div>
</div>
<div class="section" id="case-study-2-coal-mining-disasters">
<h2>Case study 2: Coal mining disasters<a class="headerlink" href="#case-study-2-coal-mining-disasters" title="Permalink to this headline">¶</a></h2>
<p>Consider the following time series of recorded coal mining disasters in the UK from 1851 to 1962 (Jarrett, 1979). The number of disasters is thought to have been affected by changes in safety regulations during this period. Unfortunately, we also have pair of years with missing data, identified as missing by a <code class="docutils literal notranslate"><span class="pre">nan</span></code> in the pandas <code class="docutils literal notranslate"><span class="pre">Series</span></code>. These missing values will be automatically imputed by <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code>.</p>
<p>Next we will build a model for this series and attempt to estimate when the change occurred. At the same time, we will see how to handle missing data, use multiple samplers and sample from discrete random variables.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">disaster_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span>
                           <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span>
                           <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
                           <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
                           <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span>
                           <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span>
                           <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">years</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1851</span><span class="p">,</span> <span class="mi">1962</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">years</span><span class="p">,</span> <span class="n">disaster_data</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Disaster count&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Year&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/PyMC3_docs_getting_started_43_0.png" src="../../_images/PyMC3_docs_getting_started_43_0.png" />
</div>
</div>
<p>Occurrences of disasters in the time series is thought to follow a Poisson process with a large rate parameter in the early part of the time series, and from one with a smaller rate in the later part. We are interested in locating the change point in the series, which perhaps is related to changes in mining safety regulations.</p>
<p>In our model,</p>
<div class="math notranslate nohighlight">
\[\begin{split} 
\begin{aligned}  
  D_t &amp;\sim \text{Pois}(r_t), r_t= \begin{cases} 
   e, &amp; \text{if } t \le s \\
   l, &amp; \text{if } t \gt s 
   \end{cases} \\
  s &amp;\sim \text{Unif}(t_l, t_h)\\         
  e &amp;\sim \text{exp}(1)\\
  l &amp;\sim \text{exp}(1)    
\end{aligned}
\end{split}\]</div>
<p>the parameters are defined as follows:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(D_t\)</span>: The number of disasters in year <span class="math notranslate nohighlight">\(t\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(r_t\)</span>: The rate parameter of the Poisson distribution of disasters in year <span class="math notranslate nohighlight">\(t\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(s\)</span>: The year in which the rate parameter changes (the switchpoint).</p></li>
<li><p><span class="math notranslate nohighlight">\(e\)</span>: The rate parameter before the switchpoint <span class="math notranslate nohighlight">\(s\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(l\)</span>: The rate parameter after the switchpoint <span class="math notranslate nohighlight">\(s\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(t_l\)</span>, <span class="math notranslate nohighlight">\(t_h\)</span>: The lower and upper boundaries of year <span class="math notranslate nohighlight">\(t\)</span>.</p></li>
</ul>
<p>This model is built much like our previous models. The major differences are the introduction of discrete variables with the Poisson and discrete-uniform priors and the novel form of the deterministic random variable <code class="docutils literal notranslate"><span class="pre">rate</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">disaster_model</span><span class="p">:</span>

    <span class="n">switchpoint</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">DiscreteUniform</span><span class="p">(</span><span class="s1">&#39;switchpoint&#39;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="n">years</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">upper</span><span class="o">=</span><span class="n">years</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">testval</span><span class="o">=</span><span class="mi">1900</span><span class="p">)</span>

    <span class="c1"># Priors for pre- and post-switch rates number of disasters</span>
    <span class="n">early_rate</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;early_rate&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">late_rate</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;late_rate&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Allocate appropriate Poisson rates to years before and after current</span>
    <span class="n">rate</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">switch</span><span class="p">(</span><span class="n">switchpoint</span> <span class="o">&gt;=</span> <span class="n">years</span><span class="p">,</span> <span class="n">early_rate</span><span class="p">,</span> <span class="n">late_rate</span><span class="p">)</span>

    <span class="n">disasters</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Poisson</span><span class="p">(</span><span class="s1">&#39;disasters&#39;</span><span class="p">,</span> <span class="n">rate</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">disaster_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/furnstah/anaconda3/envs/talent-env/lib/python3.7/site-packages/pymc3/model.py:1331: UserWarning: Data in disasters contains missing values and will be automatically imputed from the sampling distribution.
  warnings.warn(impute_message, UserWarning)
</pre></div>
</div>
</div>
</div>
<p>The logic for the rate random variable,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">rate</span> <span class="o">=</span> <span class="n">switch</span><span class="p">(</span><span class="n">switchpoint</span> <span class="o">&gt;=</span> <span class="n">year</span><span class="p">,</span> <span class="n">early_rate</span><span class="p">,</span> <span class="n">late_rate</span><span class="p">)</span>
</pre></div>
</div>
<p>is implemented using <code class="docutils literal notranslate"><span class="pre">switch</span></code>, a Theano function that works like an if statement. It uses the first argument to switch between the next two arguments.</p>
<p>Missing values are handled transparently by passing a <code class="docutils literal notranslate"><span class="pre">MaskedArray</span></code> or a <code class="docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code> with NaN values to the <code class="docutils literal notranslate"><span class="pre">observed</span></code> argument when creating an observed stochastic random variable. Behind the scenes, another random variable, <code class="docutils literal notranslate"><span class="pre">disasters.missing_values</span></code> is created to model the missing values.</p>
<p>Unfortunately because they are discrete variables and thus have no meaningful gradient, we cannot use NUTS for sampling <code class="docutils literal notranslate"><span class="pre">switchpoint</span></code> or the missing disaster observations. Instead, we will sample using a <code class="docutils literal notranslate"><span class="pre">Metroplis</span></code> step method, which implements adaptive Metropolis-Hastings, because it is designed to handle discrete values. <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> automatically assigns the correct sampling algorithms.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">disaster_model</span><span class="p">:</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Multiprocess sampling (4 chains in 4 jobs)
CompoundStep
&gt;CompoundStep
&gt;&gt;Metropolis: [disasters_missing]
&gt;&gt;Metropolis: [switchpoint]
&gt;NUTS: [late_rate, early_rate]
Sampling 4 chains: 100%|██████████| 42000/42000 [00:24&lt;00:00, 1698.71draws/s]
The number of effective samples is smaller than 10% for some parameters.
</pre></div>
</div>
</div>
</div>
<p>In the trace plot below we can see that there’s about a 10 year span that’s plausible for a significant change in safety, but a 5 year span that contains most of the probability mass. The distribution is jagged because of the jumpy relationship between the year switchpoint and the likelihood  and not due to sampling error.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pm</span><span class="o">.</span><span class="n">traceplot</span><span class="p">(</span><span class="n">trace</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/PyMC3_docs_getting_started_50_0.png" src="../../_images/PyMC3_docs_getting_started_50_0.png" />
</div>
</div>
<p>The following plot shows the switch point as an orange vertical line, together with its HPD as a semitransparent band. The dashed black line shows the accident rate.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">years</span><span class="p">,</span> <span class="n">disaster_data</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Number of accidents&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Year&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;switchpoint&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">disaster_data</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">disaster_data</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">)</span>
<span class="n">average_disasters</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">disaster_data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">year</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">years</span><span class="p">):</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">year</span> <span class="o">&lt;</span> <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;switchpoint&#39;</span><span class="p">]</span>
    <span class="n">average_disasters</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;early_rate&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">+</span> <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;late_rate&#39;</span><span class="p">][</span><span class="o">~</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span> <span class="o">*</span> <span class="n">trace</span><span class="o">.</span><span class="n">nchains</span><span class="p">)</span>

<span class="n">sp_hpd</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">hpd</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;switchpoint&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_betweenx</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="n">disaster_data</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">disaster_data</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span>
                  <span class="n">x1</span><span class="o">=</span><span class="n">sp_hpd</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x2</span><span class="o">=</span><span class="n">sp_hpd</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">years</span><span class="p">,</span> <span class="n">average_disasters</span><span class="p">,</span>  <span class="s1">&#39;k--&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/PyMC3_docs_getting_started_52_0.png" src="../../_images/PyMC3_docs_getting_started_52_0.png" />
</div>
</div>
</div>
<div class="section" id="arbitrary-deterministics">
<h2>Arbitrary deterministics<a class="headerlink" href="#arbitrary-deterministics" title="Permalink to this headline">¶</a></h2>
<p>Due to its reliance on Theano, PyMC3 provides many mathematical functions and operators for transforming random variables into new random variables. However, the library of functions in Theano is not exhaustive, therefore Theano and PyMC3 provide functionality for creating arbitrary Theano functions in pure Python, and including these functions in PyMC models. This is supported with the <code class="docutils literal notranslate"><span class="pre">as_op</span></code> function decorator.</p>
<p>Theano needs to know the types of the inputs and outputs of a function, which are specified for <code class="docutils literal notranslate"><span class="pre">as_op</span></code> by <code class="docutils literal notranslate"><span class="pre">itypes</span></code> for inputs and <code class="docutils literal notranslate"><span class="pre">otypes</span></code> for outputs. The Theano documentation includes <a class="reference external" href="http://deeplearning.net/software/theano/library/tensor/basic.html#all-fully-typed-constructors">an overview of the available types</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">theano.tensor</span> <span class="k">as</span> <span class="nn">tt</span>
<span class="kn">from</span> <span class="nn">theano.compile.ops</span> <span class="kn">import</span> <span class="n">as_op</span>

<span class="nd">@as_op</span><span class="p">(</span><span class="n">itypes</span><span class="o">=</span><span class="p">[</span><span class="n">tt</span><span class="o">.</span><span class="n">lscalar</span><span class="p">],</span> <span class="n">otypes</span><span class="o">=</span><span class="p">[</span><span class="n">tt</span><span class="o">.</span><span class="n">lscalar</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">crazy_modulo3</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> 
        <span class="k">return</span> <span class="n">value</span> <span class="o">%</span> <span class="mi">3</span>
    <span class="k">else</span> <span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="o">-</span><span class="n">value</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">3</span>
    
<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_deterministic</span><span class="p">:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Poisson</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">crazy_modulo3</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>An important drawback of this approach is that it is not possible for <code class="docutils literal notranslate"><span class="pre">theano</span></code> to inspect these functions in order to compute the gradient required for the Hamiltonian-based samplers. Therefore, it is not possible to use the HMC or NUTS samplers for a model that uses such an operator. However, it is possible to add a gradient if we inherit from <code class="docutils literal notranslate"><span class="pre">theano.Op</span></code> instead of using <code class="docutils literal notranslate"><span class="pre">as_op</span></code>. The PyMC example set includes <a class="reference external" href="https://github.com/pymc-devs/pymc3/blob/master/pymc3/examples/disaster_model_theano_op.py">a more elaborate example of the usage of as_op</a>.</p>
</div>
<div class="section" id="arbitrary-distributions">
<h2>Arbitrary distributions<a class="headerlink" href="#arbitrary-distributions" title="Permalink to this headline">¶</a></h2>
<p>Similarly, the library of statistical distributions in PyMC3 is not exhaustive, but PyMC3 allows for the creation of user-defined functions for an arbitrary probability distribution. For simple statistical distributions, the <code class="docutils literal notranslate"><span class="pre">DensityDist</span></code> function takes as an argument any function that calculates a log-probability <span class="math notranslate nohighlight">\(log(p(x))\)</span>. This function may employ other random variables in its calculation. Here is an example inspired by a blog post by Jake Vanderplas on which priors to use for a linear regression (Vanderplas, 2014).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">theano.tensor</span> <span class="k">as</span> <span class="nn">tt</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="s1">&#39;intercept&#39;</span><span class="p">,</span> <span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
    
    <span class="c1"># Create custom densities</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">DensityDist</span><span class="p">(</span><span class="s1">&#39;beta&#39;</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">value</span><span class="p">:</span> <span class="o">-</span><span class="mf">1.5</span> <span class="o">*</span> <span class="n">tt</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">value</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span> <span class="n">testval</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">eps</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">DensityDist</span><span class="p">(</span><span class="s1">&#39;eps&#39;</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">value</span><span class="p">:</span> <span class="o">-</span><span class="n">tt</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">abs_</span><span class="p">(</span><span class="n">value</span><span class="p">)),</span> <span class="n">testval</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Create likelihood</span>
    <span class="n">like</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y_est&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">alpha</span> <span class="o">+</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">X</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="n">eps</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">Y</span><span class="p">)</span>
</pre></div>
</div>
<p>For more complex distributions, one can create a subclass of <code class="docutils literal notranslate"><span class="pre">Continuous</span></code> or <code class="docutils literal notranslate"><span class="pre">Discrete</span></code> and provide the custom <code class="docutils literal notranslate"><span class="pre">logp</span></code> function, as required. This is how the built-in distributions in PyMC are specified. As an example, fields like psychology and astrophysics have complex likelihood functions for a particular process that may require numerical approximation. In these cases, it is impossible to write the function in terms of predefined theano operators and we must use a custom theano operator using <code class="docutils literal notranslate"><span class="pre">as_op</span></code> or inheriting from <code class="docutils literal notranslate"><span class="pre">theano.Op</span></code>.</p>
<p>Implementing the <code class="docutils literal notranslate"><span class="pre">beta</span></code> variable above as a <code class="docutils literal notranslate"><span class="pre">Continuous</span></code> subclass is shown below, along with a sub-function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Beta</span><span class="p">(</span><span class="n">pm</span><span class="o">.</span><span class="n">Continuous</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Beta</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mu</span>

    <span class="k">def</span> <span class="nf">logp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span>
        <span class="k">return</span> <span class="n">beta_logp</span><span class="p">(</span><span class="n">value</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span>
    

<span class="k">def</span> <span class="nf">beta_logp</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
    <span class="k">return</span> <span class="o">-</span><span class="mf">1.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">value</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>


<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">Beta</span><span class="p">(</span><span class="s1">&#39;slope&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">testval</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>If your logp can not be expressed in Theano, you can decorate the function with <code class="docutils literal notranslate"><span class="pre">as_op</span></code> as follows: <code class="docutils literal notranslate"><span class="pre">&#64;as_op(itypes=[tt.dscalar],</span> <span class="pre">otypes=[tt.dscalar])</span></code>. Note, that this will create a blackbox Python function that will be much slower and  not provide the gradients necessary for e.g. NUTS.</p>
</div>
<div class="section" id="generalized-linear-models">
<h2>Generalized Linear Models<a class="headerlink" href="#generalized-linear-models" title="Permalink to this headline">¶</a></h2>
<p>Generalized Linear Models (GLMs) are a class of flexible models that are widely used to estimate regression relationships between a single outcome variable and one or multiple predictors. Because these models are so common, <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> offers a <code class="docutils literal notranslate"><span class="pre">glm</span></code> submodule that allows flexible creation of various GLMs with an intuitive <code class="docutils literal notranslate"><span class="pre">R</span></code>-like syntax that is implemented via the <code class="docutils literal notranslate"><span class="pre">patsy</span></code> module.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">glm</span></code> submodule requires data to be included as a <code class="docutils literal notranslate"><span class="pre">pandas</span></code> <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code>. Hence, for our linear regression example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Convert X and Y to a pandas DataFrame</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;x1&#39;</span><span class="p">:</span> <span class="n">X1</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">:</span> <span class="n">X2</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">:</span> <span class="n">Y</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<p>The model can then be very concisely specified in one line of code.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pymc3.glm</span> <span class="kn">import</span> <span class="n">GLM</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_glm</span><span class="p">:</span>
    <span class="n">GLM</span><span class="o">.</span><span class="n">from_formula</span><span class="p">(</span><span class="s1">&#39;y ~ x1 + x2&#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [sd, x2, x1, Intercept]
Sampling 4 chains: 100%|██████████| 4000/4000 [00:02&lt;00:00, 1425.31draws/s]
</pre></div>
</div>
</div>
</div>
<p>The error distribution, if not specified via the <code class="docutils literal notranslate"><span class="pre">family</span></code> argument, is assumed to be normal. In the case of logistic regression, this can be modified by passing in a <code class="docutils literal notranslate"><span class="pre">Binomial</span></code> family object.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pymc3.glm.families</span> <span class="kn">import</span> <span class="n">Binomial</span>

<span class="n">df_logistic</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;x1&#39;</span><span class="p">:</span> <span class="n">X1</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">:</span> <span class="n">Y</span> <span class="o">&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">Y</span><span class="p">)})</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_glm_logistic</span><span class="p">:</span>
    <span class="n">GLM</span><span class="o">.</span><span class="n">from_formula</span><span class="p">(</span><span class="s1">&#39;y ~ x1&#39;</span><span class="p">,</span> <span class="n">df_logistic</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">Binomial</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<p>For a more complete and flexible formula interface, including hierarchical GLMs, see <a class="reference external" href="https://github.com/bambinos/bambi">Bambi</a>.</p>
</div>
<div class="section" id="discussion">
<h2>Discussion<a class="headerlink" href="#discussion" title="Permalink to this headline">¶</a></h2>
<p>Probabilistic programming is an emerging paradigm in statistical learning, of which Bayesian modeling is an important sub-discipline. The signature characteristics of probabilistic programming–specifying variables as probability distributions and conditioning variables on other variables and on observations–makes it a powerful tool for building models in a variety of settings, and over a range of model complexity. Accompanying the rise of probabilistic programming has been a burst of innovation in fitting methods for Bayesian models that represent notable improvement over existing MCMC methods. Yet, despite this expansion, there are few software packages available that have kept pace with the methodological innovation, and still fewer that allow non-expert users to implement models.</p>
<p>PyMC3 provides a probabilistic programming platform for quantitative researchers to implement statistical models flexibly and succinctly. A large library of statistical distributions and several pre-defined fitting algorithms allows users to focus on the scientific problem at hand, rather than the implementation details of Bayesian modeling. The choice of Python as a development language, rather than a domain-specific language, means that PyMC3 users are able to work interactively to build models, introspect model objects, and debug or profile their work, using a dynamic, high-level programming language that is easy to learn. The modular, object-oriented design of PyMC3 means that adding new fitting algorithms or other features is straightforward. In addition, PyMC3 comes with several features not found in most other packages, most notably Hamiltonian-based samplers as well as automatical transforms of constrained random variables which is only offered by STAN. Unlike STAN, however, PyMC3 supports discrete variables as well as non-gradient based sampling algorithms like Metropolis-Hastings and Slice sampling.</p>
<p>Development of PyMC3 is an ongoing effort and several features are planned for future versions. Most notably, variational inference techniques are often more efficient than MCMC sampling, at the cost of generalizability. More recently, however, black-box variational inference algorithms have been developed, such as automatic differentiation variational inference (ADVI; Kucukelbir et al., 2017). This algorithm is slated for addition to PyMC3. As an open-source scientific computing toolkit, we encourage researchers developing new fitting algorithms for Bayesian models to provide reference implementations in PyMC3. Since samplers can be written in pure Python code, they can be implemented generally to make them work on arbitrary PyMC3 models, giving authors a larger audience to put their methods into use.</p>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p>Patil, A., D. Huard and C.J. Fonnesbeck. (2010) PyMC: Bayesian Stochastic Modelling in Python. Journal of Statistical Software, 35(4), pp. 1-81</p>
<p>Bastien, F., Lamblin, P., Pascanu, R., Bergstra, J., Goodfellow, I., Bergeron, A., Bouchard, N., Warde-Farley, D., and Bengio, Y. (2012) “Theano: new features and speed improvements”. NIPS 2012 deep learning workshop.</p>
<p>Bergstra, J., Breuleux, O., Bastien, F., Lamblin, P., Pascanu, R., Desjardins, G., Turian, J., Warde-Farley, D., and Bengio, Y. (2010) “Theano: A CPU and GPU Math Expression Compiler”. Proceedings of the Python for Scientific Computing Conference (SciPy) 2010. June 30 - July 3, Austin, TX</p>
<p>Lunn, D.J., Thomas, A., Best, N., and Spiegelhalter, D. (2000) WinBUGS – a Bayesian modelling framework: concepts, structure, and extensibility. Statistics and Computing, 10:325–337.</p>
<p>Neal, R.M. Slice sampling. Annals of Statistics. (2003). doi:10.2307/3448413.</p>
<p>van Rossum, G. The Python Library Reference Release 2.6.5., (2010). URL <a class="reference external" href="http://docs.python.org/library/">http://docs.python.org/library/</a>.</p>
<p>Duane, S., Kennedy, A. D., Pendleton, B. J., and Roweth, D. (1987) “Hybrid Monte Carlo”, Physics Letters, vol. 195, pp. 216-222.</p>
<p>Stan Development Team. (2014). Stan: A C++ Library for Probability and Sampling, Version 2.5.0.   <a class="reference external" href="http://mc-stan.org">http://mc-stan.org</a>.</p>
<p>Gamerman, D. Markov Chain Monte Carlo: statistical simulation for Bayesian inference. Chapman and Hall, 1997.</p>
<p>Hoffman, M. D., &amp; Gelman, A. (2014). The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo. The Journal of Machine Learning Research, 30.</p>
<p>Kucukelbir A, Dustin Tran, Ranganath R, Gelman A, and Blei DM. Automatic differentiation variational inference
<a class="reference external" href="http://arxiv.org/abs/1506.03431">http://arxiv.org/abs/1506.03431</a>,  The Journal of Machine Learning Research. 18 , pp. 430-474 .</p>
<p>Vanderplas, Jake. “Frequentism and Bayesianism IV: How to be a Bayesian in Python.” Pythonic Perambulations. N.p., 14 Jun 2014. Web. 27 May. 2015. <a class="reference external" href="https://jakevdp.github.io/blog/2014/06/14/frequentism-and-bayesianism-4-bayesian-in-python/">https://jakevdp.github.io/blog/2014/06/14/frequentism-and-bayesianism-4-bayesian-in-python/</a>.</p>
<p>R.G. Jarrett. A note on the intervals between coal mining disasters. Biometrika, 66:191–193, 1979.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "furnstahl/Physics-8820",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "conda-env-talent-env-py"
        },
        kernelOptions: {
            kernelName: "conda-env-talent-env-py",
            path: "./notebooks/MCMC_sampling_II"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'conda-env-talent-env-py'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="PyMC3_intro.html" title="previous page"><span class="section-number">6.4. </span>PyMC3 Introduction</a>
    <a class='right-next' id="next-link" href="../../content/Gaussian_processes/gaussian_processes.html" title="next page"><span class="section-number">7. </span>Gaussian processes</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Dick Furnstahl<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>